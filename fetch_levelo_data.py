#!/usr/bin/env python3
"""
Script de collecte des donnÃ©es Le VÃ©lo Marseille - VERSION OPTIMISÃ‰E
- RÃ©cupÃ¨re les donnÃ©es depuis l'API GBFS Omega
- Sauvegarde dans Supabase (PostgreSQL) avec batch inserts
- Exporte en JSON pour le dashboard

Optimisations :
- Batch inserts (2 requÃªtes au lieu de 200+)
- Constantes pour les zones gÃ©ographiques
- Gestion amÃ©liorÃ©e de la capacitÃ© nulle
"""

import os
import json
import requests
from datetime import datetime
from supabase import create_client, Client

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# URLs de l'API Le VÃ©lo (GBFS Omega Fifteen)
BASE_URL = "https://gbfs.omega.fifteen.eu/gbfs/2.2/marseille/en"
STATION_STATUS_URL = f"{BASE_URL}/station_status.json"
STATION_INFO_URL = f"{BASE_URL}/station_information.json"

# Zones gÃ©ographiques de Marseille (latitude)
ZONE_NORD_LIMIT = 43.30
ZONE_CENTRE_LIMIT = 43.28

# Seuils de disponibilitÃ© pour les statuts
THRESHOLD_CRITICAL = 15
THRESHOLD_WARNING = 40
THRESHOLD_EXCELLENT = 70

# Configuration Supabase
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")

# VÃ©rification des variables d'environnement
if not SUPABASE_URL or not SUPABASE_KEY:
    print("âŒ Erreur : Variables SUPABASE_URL et SUPABASE_KEY requises")
    exit(1)

# Connexion Ã  Supabase
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FONCTIONS UTILITAIRES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def determine_zone(latitude: float) -> str:
    """
    DÃ©termine la zone gÃ©ographique en fonction de la latitude
    
    Args:
        latitude: Latitude de la station
        
    Returns:
        Nom de la zone (Nord/Centre/Sud Marseille)
    """
    if latitude >= ZONE_NORD_LIMIT:
        return 'Nord Marseille'
    elif latitude >= ZONE_CENTRE_LIMIT:
        return 'Centre Marseille'
    else:
        return 'Sud Marseille'

def calculate_status(bikes: int, capacity: int) -> str:
    """
    Calcule le statut d'affichage d'une station
    
    Args:
        bikes: Nombre de vÃ©los disponibles
        capacity: CapacitÃ© totale de la station
        
    Returns:
        Statut : critical, warning, good, excellent
    """
    if bikes == 0 or capacity == 0:
        return "critical"
    
    availability_rate = (bikes / capacity * 100)
    
    if availability_rate < THRESHOLD_CRITICAL:
        return "critical"
    elif availability_rate < THRESHOLD_WARNING:
        return "warning"
    elif availability_rate > THRESHOLD_EXCELLENT:
        return "excellent"
    else:
        return "good"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FONCTIONS PRINCIPALES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def fetch_api_data():
    """
    RÃ©cupÃ¨re les donnÃ©es depuis l'API GBFS
    
    Returns:
        Tuple (status_data, info_data) ou (None, None) en cas d'erreur
    """
    print("ğŸ“¡ RÃ©cupÃ©ration des donnÃ©es API...")
    
    try:
        # RÃ©cupÃ©rer le statut des stations
        print(f"   â†’ {STATION_STATUS_URL}")
        status_response = requests.get(STATION_STATUS_URL, timeout=10)
        status_response.raise_for_status()
        status_data = status_response.json()['data']['stations']
        print(f"   âœ… Stations status: {len(status_data)}")
        
        # RÃ©cupÃ©rer les infos des stations
        print(f"   â†’ {STATION_INFO_URL}")
        info_response = requests.get(STATION_INFO_URL, timeout=10)
        info_response.raise_for_status()
        info_data = info_response.json()['data']['stations']
        print(f"   âœ… Stations info: {len(info_data)}")
        
        print("âœ… API accessible")
        return status_data, info_data
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ Erreur API : {e}")
        return None, None

def process_data(status_data, info_data):
    """
    Fusionne et nettoie les donnÃ©es
    Calcule les mÃ©triques (taux de disponibilitÃ©, statut)
    
    Args:
        status_data: DonnÃ©es de statut des stations
        info_data: Informations des stations
        
    Returns:
        Liste des enregistrements traitÃ©s
    """
    print("ğŸ”„ Traitement des donnÃ©es...")
    
    # CrÃ©er un dictionnaire des infos par station_id (O(N) au lieu de O(NÂ²))
    info_dict = {station['station_id']: station for station in info_data}
    
    processed = []
    
    for status in status_data:
        station_id = status['station_id']
        info = info_dict.get(station_id, {})
        
        # RÃ©cupÃ©rer les valeurs (avec gestion amÃ©liorÃ©e de la capacitÃ©)
        bikes = status.get('num_bikes_available', 0)
        stands = status.get('num_docks_available', 0)
        capacity = info.get('capacity', 0) or 0  # GÃ¨re None et 0
        
        # Calculer le taux de disponibilitÃ©
        availability_rate = round((bikes / capacity * 100), 1) if capacity > 0 else 0.0
        
        # DÃ©terminer le statut d'affichage
        display_status = calculate_status(bikes, capacity)
        
        # CrÃ©er l'enregistrement
        record = {
            'station_id': station_id,
            'station_name': info.get('name', 'Station inconnue'),
            'address': info.get('address', 'Adresse non disponible'),
            'latitude': info.get('lat', 0.0),
            'longitude': info.get('lon', 0.0),
            'available_bikes': bikes,
            'available_stands': stands,
            'total_capacity': capacity,
            'status': status.get('status', 'unknown'),
            'display_status': display_status,
            'availability_rate': availability_rate,
            'last_update': datetime.now().isoformat()
        }
        
        processed.append(record)
    
    print(f"âœ… {len(processed)} stations traitÃ©es")
    
    # Afficher un exemple pour debug
    if processed:
        example = processed[0]
        print(f"   ğŸ“ Exemple: {example['station_name']} - {example['available_bikes']}/{example['total_capacity']} vÃ©los")
    
    return processed

def save_to_supabase(data):
    """
    Sauvegarde dans Supabase avec batch inserts (OPTIMISÃ‰)
    
    Architecture :
    - stations_metadata : informations statiques (UPSERT batch)
    - levelo_observations : donnÃ©es dynamiques (INSERT batch)
    
    Args:
        data: Liste des enregistrements Ã  sauvegarder
        
    Returns:
        True si succÃ¨s, False sinon
    """
    print("ğŸ’¾ Sauvegarde dans Supabase (batch inserts)...")
    
    # PrÃ©parer les batches
    metadata_batch = []
    observations_batch = []
    
    for record in data:
        station_id = record['station_id']
        
        # DÃ©terminer la zone gÃ©ographique
        zone = determine_zone(record['latitude'])
        
        # Batch 1 : MÃ©tadonnÃ©es des stations
        metadata_batch.append({
            'station_id': station_id,
            'station_name': record['station_name'],
            'address': record['address'],
            'latitude': record['latitude'],
            'longitude': record['longitude'],
            'total_capacity': record['total_capacity'],
            'zone': zone,
            'updated_at': datetime.now().isoformat()
        })
        
        # Batch 2 : Observations
        observations_batch.append({
            'station_id': station_id,
            'available_bikes': record['available_bikes'],
            'available_stands': record['available_stands'],
            'status': record['status']
        })
    
    # ExÃ©cuter les batch inserts
    saved_metadata = 0
    saved_observations = 0
    
    # 1. UPSERT batch metadata (1 seule requÃªte)
    try:
        print(f"   â†’ Upsert {len(metadata_batch)} mÃ©tadonnÃ©es...")
        supabase.table('stations_metadata').upsert(
            metadata_batch, 
            on_conflict='station_id'
        ).execute()
        saved_metadata = len(metadata_batch)
        print(f"   âœ… {saved_metadata} mÃ©tadonnÃ©es mises Ã  jour")
    except Exception as e:
        print(f"   âŒ Erreur UPSERT batch metadata: {e}")
        return False
    
    # 2. INSERT batch observations (1 seule requÃªte)
    try:
        print(f"   â†’ Insert {len(observations_batch)} observations...")
        supabase.table('levelo_observations').insert(observations_batch).execute()
        saved_observations = len(observations_batch)
        print(f"   âœ… {saved_observations} observations insÃ©rÃ©es")
    except Exception as e:
        print(f"   âŒ Erreur INSERT batch observations: {e}")
        return False
    
    print(f"âœ… Sauvegarde terminÃ©e : {saved_metadata} stations, {saved_observations} observations")
    return True

def export_json(data):
    """
    Exporte les donnÃ©es en JSON pour le dashboard Dust
    
    Args:
        data: Liste des enregistrements Ã  exporter
        
    Returns:
        True si succÃ¨s, False sinon
    """
    print("ğŸ’¾ Export JSON...")
    
    try:
        # CrÃ©er le dossier data s'il n'existe pas
        os.makedirs('data', exist_ok=True)
        
        # Sauvegarder en JSON
        output_file = 'data/levelo_data.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        # Calculer la taille du fichier
        file_size = os.path.getsize(output_file)
        file_size_kb = file_size / 1024
        
        print(f"âœ… JSON exportÃ© : {len(data)} stations ({file_size_kb:.1f} KB)")
        print(f"   ğŸ“ Fichier : {output_file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur export JSON : {e}")
        return False

def main():
    """
    Fonction principale - Orchestration du workflow
    """
    print("=" * 70)
    print("ğŸš´ COLLECTE DONNÃ‰ES LE VÃ‰LO MARSEILLE (VERSION OPTIMISÃ‰E)")
    print("=" * 70)
    print(f"â° DÃ©but : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # 1. RÃ©cupÃ©rer les donnÃ©es de l'API
    status_data, info_data = fetch_api_data()
    
    if not status_data or not info_data:
        print("âŒ Impossible de rÃ©cupÃ©rer les donnÃ©es API")
        exit(1)
    
    # 2. Traiter les donnÃ©es
    processed_data = process_data(status_data, info_data)
    
    if not processed_data:
        print("âŒ Aucune donnÃ©e Ã  traiter")
        exit(1)
    
    # 3. Sauvegarder dans Supabase (batch inserts)
    supabase_success = save_to_supabase(processed_data)
    
    if not supabase_success:
        print("âŒ Erreur lors de la sauvegarde Supabase")
        exit(1)
    
    # 4. Exporter en JSON (pour le dashboard)
    json_success = export_json(processed_data)
    
    if not json_success:
        print("âš ï¸  Erreur lors de l'export JSON (non bloquant)")
    
    # 5. RÃ©sumÃ©
    print()
    print("=" * 70)
    print("âœ… Collecte terminÃ©e avec succÃ¨s !")
    print(f"   ğŸ“Š {len(processed_data)} stations traitÃ©es")
    print(f"   ğŸ’¾ 2 requÃªtes SQL (batch inserts)")
    print(f"   ğŸ“ JSON exportÃ©")
    print(f"â° Fin : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# POINT D'ENTRÃ‰E
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    main()
