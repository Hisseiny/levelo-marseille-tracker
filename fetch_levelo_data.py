#!/usr/bin/env python3
"""
Script de collecte des donnÃ©es Le VÃ©lo Marseille
- RÃ©cupÃ¨re les donnÃ©es depuis l'API GBFS
- Sauvegarde dans Supabase (PostgreSQL)
- Exporte en JSON pour le dashboard
"""

import os
import json
import requests
from datetime import datetime
from supabase import create_client, Client

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# URLs de l'API Le VÃ©lo (GBFS - General Bikeshare Feed Specification)
BASE_URL = "https://gbfs.fifteen.eu/marseille"
STATION_STATUS_URL = f"{BASE_URL}/gbfs/2/fr/station_status"
STATION_INFO_URL = f"{BASE_URL}/gbfs/2/fr/station_information"

# Configuration Supabase
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")

# VÃ©rification des variables d'environnement
if not SUPABASE_URL or not SUPABASE_KEY:
    print("âŒ Erreur : Variables SUPABASE_URL et SUPABASE_KEY requises")
    exit(1)

# Connexion Ã  Supabase
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FONCTIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def fetch_api_data():
    """
    RÃ©cupÃ¨re les donnÃ©es depuis l'API GBFS
    Retourne : (status_data, info_data) ou (None, None) en cas d'erreur
    """
    print("ğŸ“¡ RÃ©cupÃ©ration des donnÃ©es API...")
    
    try:
        # RÃ©cupÃ©rer le statut des stations (vÃ©los disponibles en temps rÃ©el)
        print(f"   â†’ {STATION_STATUS_URL}")
        status_response = requests.get(STATION_STATUS_URL, timeout=10)
        status_response.raise_for_status()
        status_data = status_response.json()['data']['stations']
        print(f"   âœ… Stations status: {len(status_data)}")
        
        # RÃ©cupÃ©rer les infos des stations (nom, adresse, capacitÃ©)
        print(f"   â†’ {STATION_INFO_URL}")
        info_response = requests.get(STATION_INFO_URL, timeout=10)
        info_response.raise_for_status()
        info_data = info_response.json()['data']['stations']
        print(f"   âœ… Stations info: {len(info_data)}")
        
        print("âœ… API accessible")
        return status_data, info_data
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ Erreur API : {e}")
        return None, None

def process_data(status_data, info_data):
    """
    Fusionne et nettoie les donnÃ©es
    Calcule les mÃ©triques (taux de disponibilitÃ©, statut)
    """
    print("ğŸ”„ Traitement des donnÃ©es...")
    
    # CrÃ©er un dictionnaire des infos par station_id
    info_dict = {station['station_id']: station for station in info_data}
    
    processed = []
    
    for status in status_data:
        station_id = status['station_id']
        info = info_dict.get(station_id, {})
        
        # RÃ©cupÃ©rer les valeurs
        bikes = status.get('num_bikes_available', 0)
        stands = status.get('num_docks_available', 0)
        capacity = info.get('capacity', 1)
        
        # Calculer le taux de disponibilitÃ©
        availability_rate = round((bikes / capacity * 100), 1) if capacity > 0 else 0
        
        # DÃ©terminer le statut d'affichage
        if bikes == 0:
            display_status = "critical"
        elif stands == 0:
            display_status = "critical"
        elif availability_rate < 15:
            display_status = "critical"
        elif availability_rate < 40:
            display_status = "warning"
        elif availability_rate > 70:
            display_status = "excellent"
        else:
            display_status = "good"
        
        # CrÃ©er l'enregistrement
        record = {
            'station_id': station_id,
            'station_name': info.get('name', 'Station inconnue'),
            'address': info.get('address', 'Adresse non disponible'),
            'latitude': info.get('lat', 0),
            'longitude': info.get('lon', 0),
            'available_bikes': bikes,
            'available_stands': stands,
            'total_capacity': capacity,
            'status': status.get('status', 'unknown'),
            'display_status': display_status,
            'availability_rate': availability_rate,
            'last_update': datetime.now().isoformat()
        }
        
        processed.append(record)
    
    print(f"âœ… {len(processed)} stations traitÃ©es")
    
    # Afficher un exemple pour debug
    if processed:
        example = processed[0]
        print(f"   ğŸ“ Exemple: {example['station_name']} - {example['available_bikes']} vÃ©los")
    
    return processed

def save_to_supabase(data):
    """
    Sauvegarde dans la nouvelle structure Ã  2 tables
    - stations_metadata : informations statiques (nom, adresse, capacitÃ©)
    - levelo_observations : donnÃ©es dynamiques (vÃ©los disponibles)
    """
    print("ğŸ’¾ Sauvegarde dans Supabase (nouvelle structure)...")
    
    saved_metadata = 0
    saved_observations = 0
    errors = []
    
    for record in data:
        try:
            station_id = record['station_id']
            
            # DÃ©terminer la zone gÃ©ographique
            lat = record['latitude']
            if lat >= 43.30:
                zone = 'Nord Marseille'
            elif lat >= 43.28:
                zone = 'Centre Marseille'
            else:
                zone = 'Sud Marseille'
            
            # 1. UPSERT dans stations_metadata
            # (mise Ã  jour si existe, insertion sinon)
            supabase.table('stations_metadata').upsert({
                'station_id': station_id,
                'station_name': record['station_name'],
                'address': record['address'],
                'latitude': record['latitude'],
                'longitude': record['longitude'],
                'total_capacity': record['total_capacity'],
                'zone': zone,
                'updated_at': datetime.now().isoformat()
            }, on_conflict='station_id').execute()
            
            saved_metadata += 1
            
            # 2. INSERT dans levelo_observations
            # (toujours une nouvelle ligne pour l'historique)
            supabase.table('levelo_observations').insert({
                'station_id': station_id,
                'available_bikes': record['available_bikes'],
                'available_stands': record['available_stands'],
                'status': record['status']
            }).execute()
            
            saved_observations += 1
            
        except Exception as e:
            error_msg = f"Station {station_id}: {str(e)}"
            errors.append(error_msg)
            print(f"âš ï¸  {error_msg}")
            continue
    
    print(f"âœ… {saved_metadata} mÃ©tadonnÃ©es mises Ã  jour")
    print(f"âœ… {saved_observations} observations insÃ©rÃ©es")
    
    if errors:
        print(f"âš ï¸  {len(errors)} erreurs rencontrÃ©es")
    
    return saved_observations > 0

def export_json(data):
    """
    Exporte les donnÃ©es en JSON pour le dashboard Dust
    """
    print("ğŸ’¾ Export JSON...")
    
    try:
        # CrÃ©er le dossier data s'il n'existe pas
        os.makedirs('data', exist_ok=True)
        
        # Sauvegarder en JSON
        output_file = 'data/levelo_data.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… JSON exportÃ© : {len(data)} stations")
        print(f"   ğŸ“ Fichier : {output_file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur export JSON : {e}")
        return False

def main():
    """
    Fonction principale
    """
    print("=" * 70)
    print("ğŸš´ COLLECTE DONNÃ‰ES LE VÃ‰LO MARSEILLE")
    print("=" * 70)
    print(f"â° DÃ©but : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # 1. RÃ©cupÃ©rer les donnÃ©es de l'API
    status_data, info_data = fetch_api_data()
    
    if not status_data or not info_data:
        print("âŒ Impossible de rÃ©cupÃ©rer les donnÃ©es API")
        exit(1)
    
    # 2. Traiter les donnÃ©es
    processed_data = process_data(status_data, info_data)
    
    if not processed_data:
        print("âŒ Aucune donnÃ©e Ã  traiter")
        exit(1)
    
    # 3. Sauvegarder dans Supabase
    supabase_success = save_to_supabase(processed_data)
    
    if not supabase_success:
        print("âš ï¸  Erreur lors de la sauvegarde Supabase")
    
    # 4. Exporter en JSON (pour le dashboard)
    json_success = export_json(processed_data)
    
    if not json_success:
        print("âš ï¸  Erreur lors de l'export JSON")
    
    # 5. RÃ©sumÃ©
    print()
    print("=" * 70)
    if supabase_success and json_success:
        print("âœ… Collecte terminÃ©e avec succÃ¨s !")
    else:
        print("âš ï¸  Collecte terminÃ©e avec des avertissements")
    print(f"â° Fin : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# POINT D'ENTRÃ‰E
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    main()
